{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Driver Data - Exploration in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "This data set was created to help Kaggle users in the New Your City Taxi Trip Duration competition. New features were generated using Wolfram Mathematica system.\n",
    "Hope that this data set will help both young and experienced researchers in their data mastering path.\n",
    "\n",
    "### Content\n",
    "\n",
    "Given dataset consists of both features from initial dataset and generated via Wolfram Mathematica computational system. Thus, all features can be split into following groups:\n",
    "\n",
    "* Initial features (extracted from initial data),\n",
    "* Calendar features (contains of season, day name and day period),\n",
    "* Weather features (information about temperature, snow, and rain),\n",
    "* Travel features (geo distance with estimated driving distance and time).\n",
    "\n",
    "#### Dataset contains the following columns:\n",
    "* `id` - a unique identifier for each trip,\n",
    "* `vendorId` - a code indicating the provider associated with the trip record,\n",
    "* `passengerCount` - the number of passengers in the vehicle (driver entered value),\n",
    "* `year`,\n",
    "* `month`,\n",
    "* `day`,\n",
    "* `hour`,\n",
    "* `minute`,\n",
    "* `second`,\n",
    "* `season`,\n",
    "* `dayName`,\n",
    "* `dayPeriod` - day period, e.g. late night, morning, and etc.,\n",
    "* `temperature`,\n",
    "* `rain`,\n",
    "* `snow`,\n",
    "* `startLatitude`,\n",
    "* `startLongitude`,\n",
    "* `endLatitude`,\n",
    "* `endLongitude`,\n",
    "* `flag` - this flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip,\n",
    "* `drivingDistance` - driving distance, estimated via Wolfram Mathematica system,\n",
    "* `drivingTime` - driving time, estimated via Wolfram Mathematica system,\n",
    "* `geoDistance` - distance between starting and ending points,\n",
    "* `tripDuration` - duration of the trip in seconds (value -1 indicates test rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first block of code imports the various modules and uses the `openml` API to download the specific dataset from the website. It is stored as a panda dataframe in the variable X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# List all datasets and their properties\n",
    "openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "\n",
    "# Get dataset by ID\n",
    "dataset = openml.datasets.get_dataset(43584)\n",
    "\n",
    "# Get the data itself as a dataframe (or otherwise)\n",
    "X, y, _, _ = dataset.get_data(dataset_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check first that the data is presenting as we would have expected, by printing the first five rows of the panda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🚧 `.dtypes` does not have parentheses after it.\n",
    "\n",
    "By running this, we check also that the data are formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[X['tripDuration'] == -1]) / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description mentioned that the value of `-1` indicates test rows. We can see that $30\\%$ of the rows are specified as test rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(date=pd.to_datetime(X[[\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have date and time data, but they are separated into separate columns for each component. We can combine them into a single column, and then convert them to a datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.plot('date', 'drivingTime', kind='scatter')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Driving time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first plot merely scatters the full datetime column along the bottom against the driving time. The presence of a very small number of extreme outliers obscures any trend in the main body of the data. Almost every journey is less than one hour; most are less than half an hour, so the extension of the $y$-axis to 13 hours is not helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['drivingTime'] > 40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slice the dataset to isolate this one point above 40000 seconds. By plotting the latitude and longitude of the start and end points, we can see that the journey is from the centre of New York to Quebec. Google Maps roughly agrees with the driving time, so the data are likely correct, though ridiculous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![map](map.png)\n",
    "\n",
    "We can see that this outlier data point is a 13-hour trip from New York to the north of Quebec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_driving_time = X.groupby('hour')['drivingTime'].mean()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then find the mean driving time for each hour of the day, in order to plot it and see the average journey time during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_driving_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(0,24), mean_driving_time)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Mean Driving Time')\n",
    "plt.title('Journey time at different times of day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots the mean driving time against each hour of the day as a bar chart, so we can compare the average journey time during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the median driving time for each hour of the day.\n",
    "\n",
    "median_driving_time = X.groupby('hour')['drivingTime'].median()/60\n",
    "median_driving_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(0,24), median_driving_time)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Median Driving Time (minutes)')\n",
    "plt.title('Median Driving Time vs. Hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same plot, but with the median plotted instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_date = X['date'][0].date()\n",
    "\n",
    "# Update the 'date' column with the same date for all rows\n",
    "X['date'] = X['date'].apply(lambda x: x.replace(year=base_date.year, month=base_date.month, day=base_date.day))\n",
    "\n",
    "# Output the DataFrame with updated 'date' column\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temporary hack, the date is made to be on the same day for all journeys, so that the time of day can be plotted against the driving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['date'] = X['date'].dt.floor('10min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time is then rounded into 10-minute buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_driving_time_by_minute = X.groupby('date')['drivingTime'].mean()/60\n",
    "mean_driving_time_by_minute_std = X.groupby('date')['drivingTime'].std()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new series is created which has the mean driving time in minutes for each 10 minute interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_time = datetime.strptime(\"00:00\", \"%H:%M\")\n",
    "end_time = datetime.strptime(\"23:59\", \"%H:%M\")\n",
    "step = timedelta(minutes=10)\n",
    "times = []\n",
    "\n",
    "current_time = start_time\n",
    "date_prefix = \"2016-01-01\"\n",
    "\n",
    "while current_time <= end_time:\n",
    "    formatted_time = current_time.strftime(\"%H:%M\")\n",
    "    times.append(f\"{date_prefix} {formatted_time}:00\")\n",
    "    current_time += step\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.DataFrame(times)\n",
    "times = pd.to_datetime(times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells create a series with each 10-minute time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(times, mean_driving_time_by_minute, width=0.007, edgecolor='none', color='red')\n",
    "plt.ylim(3, 6.5)\n",
    "plt.xlabel('Time of day, in 10-minute buckets')\n",
    "plt.ylabel('Mean driving time (minutes)')\n",
    "plt.title('Length of taxi drives throughout the day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is a bar chart showing the mean driving time for each 10-minute interval of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(times.to_numpy(), mean_driving_time_by_minute.to_numpy())\n",
    "plt.ylim(3, 6.5)\n",
    "plt.xlabel('Time of day, in 10-minute buckets')\n",
    "plt.ylabel('Mean driving time (minutes)')\n",
    "plt.title('Length of taxi drives throughout the day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a line graph instead of a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, ax, title, y_label):\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.plot(x, y)\n",
    "    ax.margins(x=0, y=0)\n",
    "    \n",
    "def plotWithStd(x, y, stds, ax, title, y_label):\n",
    "    ax.fill_between(x, y - stds, y + stds, alpha=0.2)\n",
    "    plot(x, y, ax, title, y_label)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(7, 3), dpi=300)\n",
    "title = 'Line graph'\n",
    "stds1 = mean_driving_time_by_minute.std()\n",
    "plotWithStd(times.to_numpy(), mean_driving_time_by_minute.to_numpy(), mean_driving_time_by_minute_std.to_numpy()/5, ax1, 'Mean driving time with standard deviation', 'Driving time (minutes)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph with standard deviation added. We can see that it's fairly constant throughout the day. Standard deviation is divided by 5 for clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folium - using maps to display geographical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "m = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "while i < len(X):\n",
    "    folium.Marker([X['startLatitude'][i], X['startLongitude'][i]], icon=folium.Icon(color=\"green\", icon=\"play\")).add_to(m)\n",
    "    i += 100\n",
    "i = 0\n",
    "while i < len(X):\n",
    "    folium.Marker([X['endLatitude'][i], X['endLongitude'][i]], icon=folium.Icon(color=\"red\", icon=\"stop\")).add_to(m)\n",
    "    i += 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the folium module and creates a map centred on New York city. Using a `while` loop, it adds a green marker at every start point and a red marker at every end point, based on the latitude and longitude data stored in the dataset. There are so many datapoints that only 1% are plotted (every 100th row), as the folium module is so heavy that it otherwise crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL UNLESS ALL WORK IS SAVED AND JUPYTER IS RUNNING IN THE BROWSER. MOST LIKELY THIS WILL CRASH VSCODE AND PREVENT YOU FROM REOPENING THE PROJECT.\n",
    "\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't display the interactive map here as it crashes the system, but here is a screenshot of the map with a full 1% of the data points plotted.\n",
    "\n",
    "![map](nymap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_points = folium.Map(location=[40.7128, -74.0060], zoom_start=12, tiles='Stamen Toner')\n",
    "end_points = folium.Map(location=[40.7128, -74.0060], zoom_start=12, tiles='Stamen Toner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code makes folium maps (using the 'Stamen Toner' tiles) centred on New York. One is designated for the start points of taxi rides, and one for the end points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_data_start = X[[\"startLatitude\",\"startLongitude\"]].to_dict(orient='tight')[\"data\"]\n",
    "heat_data_end = X[[\"endLatitude\",\"endLongitude\"]].to_dict(orient='tight')[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then iterate through each row of the X dataframe, pulling the latitude and longitude of the start points into one variable, and the end points into another. The format of these variable is a list of lists, with each sublist containing the latitude and longitude of a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HeatMap(heat_data_start).add_to(start_points)\n",
    "HeatMap(heat_data_end).add_to(end_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HeatMap` plugin can be used to import the heatmap data and add it to the maps we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Un-comment these lines to display the maps\n",
    "\n",
    "start_points\n",
    "# end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cells of $111\\times 111 \\text{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X\n",
    "Y['startLatitude'] = np.floor(Y['startLatitude']*1000)/1000\n",
    "Y['endLatitude'] = np.floor(Y['endLatitude']*1000)/1000\n",
    "Y['startLongitude'] = np.floor(Y['startLongitude']*1000)/1000\n",
    "Y['endLongitude'] = np.floor(Y['endLongitude']*1000)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a duplicate dataset called `Y`, this code rounds each latitude and longitude value to 0.001, equivalent to 111m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ystart_points = folium.Map(location=[40.7128, -74.0060], zoom_start=12, tiles='Stamen Toner')\n",
    "Yend_points = folium.Map(location=[40.7128, -74.0060], zoom_start=12, tiles=\"Stamen Toner\")\n",
    "Yheat_data_start = Y[[\"startLatitude\",\"startLongitude\"]].to_dict(orient='tight')[\"data\"]\n",
    "Yheat_data_end = Y[[\"endLatitude\",\"endLongitude\"]].to_dict(orient='tight')[\"data\"]\n",
    "HeatMap(Yheat_data_start).add_to(Ystart_points)\n",
    "HeatMap(Yheat_data_end).add_to(Yend_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then repeat the above process of creating a heatmap, but using the new dataset `Y` instead of `X`. This is only a test to show that the data points are in the new, rounded grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ystart_points\n",
    "# Yend_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting how many journeys start and end in each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗ Parts of the following code may be redundant, but they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['startPos'] = Y['startLatitude'].astype(str) + ',' + Y['startLongitude'].astype(str)\n",
    "Y['endPos'] = Y['endLatitude'].astype(str) + ',' + Y['endLongitude'].astype(str)\n",
    "start_point_counts = Y.groupby('startPos').size().reset_index(name='startCount')\n",
    "end_point_counts = Y.groupby('endPos').size().reset_index(name='endCount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a new column in Y, the `startPos` and `endPos`, a composite of the two latitude and longitude columns. New dataframes are created to hold the number of starts in each cell, and the number of ends in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point_counts['latitude'] = start_point_counts['startPos'].str.split(',').str[0].astype(float)\n",
    "sorted_start_point_counts = start_point_counts.sort_values(by='latitude', ascending=True)\n",
    "start_point_counts = sorted_start_point_counts.drop('latitude', axis=1)\n",
    "\n",
    "end_point_counts['latitude'] = end_point_counts['endPos'].str.split(',').str[0].astype(float)\n",
    "sorted_end_point_counts = end_point_counts.sort_values(by='latitude', ascending=True)\n",
    "end_point_counts = sorted_end_point_counts.drop('latitude', axis=1)\n",
    "\n",
    "start_point_counts = start_point_counts.rename(columns={'startPos': 'pos'})\n",
    "end_point_counts = end_point_counts.rename(columns={'endPos': 'pos'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell then sorts the points and renames the position columns to `pos` in both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataframe is working as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_points = pd.merge(\n",
    "    start_point_counts, end_point_counts, how=\"outer\"\n",
    ")\n",
    "\n",
    "full_points = full_points.fillna(0)\n",
    "full_points['netCount'] = full_points['startCount'] - full_points['endCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we merge both databases to create a new datframe containing every point (nearest 111m) where a journey either starts or ends. It contains columns for the number of journeys that start and end at that point, and then a value with the difference between the two, giving us a value that is positive if more journeys start there, and negative if more journeys end there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe runs as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_points['latitude'] = full_points['pos'].str.split(',').str[0].astype(float)\n",
    "full_points['longitude'] = full_points['pos'].str.split(',').str[1].astype(float)\n",
    "full_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the position column is split into latitude and longitude floats that we can plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "ny = gpd.GeoDataFrame([], geometry=[Polygon([[-74.25, 40.5], [-73.5, 40.5], [-73.5, 41.1], [-74.25, 41.1]])])\n",
    "gdf = gpd.GeoDataFrame(full_points, geometry=gpd.points_from_xy(full_points.longitude, full_points.latitude))\n",
    "join:gpd.GeoDataFrame = gpd.sjoin(gdf, ny, how=\"inner\", op='intersects')\n",
    "fig = join.plot(markersize=0.1, column=\"netCount\", legend=True, figsize=(10,10), vmin=-5, vmax=5)\n",
    "plt.title('New York City Taxis: Balance of Journeys Starting and Ending')\n",
    "plt.savefig('taximap.png', dpi=1000)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the `geopandas` module to plot our latitude and longitude points using `matplotlib`. We create a polygon, a rectangle containing all the value we want to see, and spatially join it with our dataset to exclude points far outside the New York area. The datapoints are then plotted on the map using a colour scale to indicate whether more journeys start or end at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hi-res plot](taximap.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
